{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMzz2cGLuZ1A"
      },
      "source": [
        "<a href=\"http://cocl.us/pytorch_link_top?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork20647850-2021-01-01\">\n",
        "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/Pytochtop.png\" width=\"750\" alt=\"IBM Product \" />\n",
        "</a> \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvUmx9oruZ1C"
      },
      "source": [
        "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/cc-logo-square.png\" width=\"200\" alt=\"cognitiveclass.ai logo\" />\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmHvKrmduZ1D"
      },
      "source": [
        "<h1><h1>Pre-trained-Models with PyTorch </h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCzc3F3XuZ1E"
      },
      "source": [
        "In this lab, you will use pre-trained models to classify between the negative and positive samples; you will be provided with the dataset object. The particular pre-trained model will be resnet18; you will have three questions:\n",
        "\n",
        "<ul>\n",
        "<li>change the output layer</li>\n",
        "<li> train the model</li> \n",
        "<li>  identify  several  misclassified samples</li> \n",
        " </ul>\n",
        "You will take several screenshots of your work and share your notebook. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0Dik3nKuZ1E"
      },
      "source": [
        "<h2>Table of Contents</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXNs1hBUuZ1F"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
        "\n",
        "<ul>\n",
        "    <li><a href=\"https://#download_data\"> Download Data</a></li>\n",
        "    <li><a href=\"https://#auxiliary\"> Imports and Auxiliary Functions </a></li>\n",
        "    <li><a href=\"https://#data_class\"> Dataset Class</a></li>\n",
        "    <li><a href=\"https://#Question_1\">Question 1</a></li>\n",
        "    <li><a href=\"https://#Question_2\">Question 2</a></li>\n",
        "    <li><a href=\"https://#Question_3\">Question 3</a></li>\n",
        "</ul>\n",
        "<p>Estimated Time Needed: <strong>120 min</strong></p>\n",
        " </div>\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPvEWkCwuZ1F"
      },
      "source": [
        "<h2 id=\"download_data\">Download Data</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIlZASwluZ1G"
      },
      "source": [
        "Download the dataset and unzip the files in your data directory, unlike the other labs, all the data will be deleted after you close  the lab, this may take some time:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcoJ0bTouZ1G",
        "outputId": "77377678-9c5c-4763-eead-27c8805b6f47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-27 10:09:49--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Positive_tensors.zip\n",
            "Resolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n",
            "Connecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2598656062 (2.4G) [application/zip]\n",
            "Saving to: ‘Positive_tensors.zip’\n",
            "\n",
            "Positive_tensors.zi 100%[===================>]   2.42G  26.5MB/s    in 83s     \n",
            "\n",
            "2022-03-27 10:11:12 (29.9 MB/s) - ‘Positive_tensors.zip’ saved [2598656062/2598656062]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Positive_tensors.zip \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kg9m9p0LuZ1I"
      },
      "outputs": [],
      "source": [
        "!unzip -q Positive_tensors.zip "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7OZ6w3-uZ1J",
        "outputId": "37c57070-3f87-44d3-ce6d-455ce066d392"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-27 10:13:13--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Negative_tensors.zip\n",
            "Resolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n",
            "Connecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2111408108 (2.0G) [application/zip]\n",
            "Saving to: ‘Negative_tensors.zip’\n",
            "\n",
            "Negative_tensors.zi 100%[===================>]   1.97G  28.9MB/s    in 71s     \n",
            "\n",
            "2022-03-27 10:14:24 (28.5 MB/s) - ‘Negative_tensors.zip’ saved [2111408108/2111408108]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Negative_tensors.zip\n",
        "!unzip -q Negative_tensors.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_3VVbyzuZ1J"
      },
      "source": [
        "We will install torchvision:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7ixGnB1uZ1K",
        "outputId": "dd905f64-5ebc-4230-d807-20665c957d82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n",
            "Requirement already satisfied: torch==1.10.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.10.0+cu111)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0->torchvision) (3.10.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfbKtmLZuZ1K"
      },
      "source": [
        "<h2 id=\"auxiliary\">Imports and Auxiliary Functions</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwSS9iKEuZ1L"
      },
      "source": [
        "The following are the libraries we are going to use for this lab. The <code>torch.manual_seed()</code> is for forcing the random function to give the same number every time we try to recompile it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zS6x9TRVuZ1L",
        "outputId": "e25276c7-4db3-4984-c8f3-54afbfbbd399"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7efb53bf4e70>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# These are the libraries will be used for this lab.\n",
        "import torchvision.models as models\n",
        "from PIL import Image\n",
        "import pandas\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import torch \n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import h5py\n",
        "import os\n",
        "import glob\n",
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "KUBUoGeRuZ1M"
      },
      "outputs": [],
      "source": [
        "from matplotlib.pyplot import imshow\n",
        "import matplotlib.pylab as plt\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWkblJT3uZ1M"
      },
      "source": [
        "<!--Empty Space for separating topics-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9Rk7_ZkuZ1N"
      },
      "source": [
        "<h2 id=\"data_class\">Dataset Class</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-GMR8dXuZ1N"
      },
      "source": [
        "This dataset class is essentially the same dataset you build in the previous section, but to speed things up, we are going to use tensors instead of jpeg images. Therefor for each iteration, you will skip the reshape step, conversion step to tensors and normalization step.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6Py6TktuZ1O",
        "outputId": "34c1b42f-627b-4730-9c7a-5b186fa635e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ],
      "source": [
        "# Create your own dataset object\n",
        "\n",
        "class Dataset(Dataset):\n",
        "\n",
        "    # Constructor\n",
        "    def __init__(self,transform=None,train=True):\n",
        "        directory= os.getcwd()\n",
        "        positive=\"Positive_tensors\"\n",
        "        negative='Negative_tensors'\n",
        "\n",
        "        positive_file_path=os.path.join(directory,positive)\n",
        "        negative_file_path=os.path.join(directory,negative)\n",
        "        positive_files=[os.path.join(positive_file_path,file) for file in os.listdir(positive_file_path) if file.endswith(\".pt\")]\n",
        "        negative_files=[os.path.join(negative_file_path,file) for file in os.listdir(negative_file_path) if file.endswith(\".pt\")]\n",
        "        number_of_samples=len(positive_files)+len(negative_files)\n",
        "        self.all_files=[None]*number_of_samples\n",
        "        self.all_files[::2]=positive_files\n",
        "        self.all_files[1::2]=negative_files \n",
        "        # The transform is goint to be used on image\n",
        "        self.transform = transform\n",
        "        #torch.LongTensor\n",
        "        self.Y=torch.zeros([number_of_samples]).type(torch.LongTensor)\n",
        "        self.Y[::2]=1\n",
        "        self.Y[1::2]=0\n",
        "        \n",
        "        if train:\n",
        "            self.all_files=self.all_files[0:30000]\n",
        "            self.Y=self.Y[0:30000]\n",
        "            self.len=len(self.all_files)\n",
        "        else:\n",
        "            self.all_files=self.all_files[30000:]\n",
        "            self.Y=self.Y[30000:]\n",
        "            self.len=len(self.all_files)     \n",
        "       \n",
        "    # Get the length\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "    \n",
        "    # Getter\n",
        "    def __getitem__(self, idx):\n",
        "               \n",
        "        image=torch.load(self.all_files[idx])\n",
        "        y=self.Y[idx]\n",
        "                  \n",
        "        # If there is any transform method, apply it onto the image\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, y\n",
        "    \n",
        "print(\"done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJlq687euZ1O"
      },
      "source": [
        "We create two dataset objects, one for the training data and one for the validation data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snOcYMfruZ1P",
        "outputId": "a57dcce0-4274-4a13-db47-6f1bef7f4a05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ],
      "source": [
        "train_dataset = Dataset(train=True)\n",
        "validation_dataset = Dataset(train=False)\n",
        "print(\"done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvW7fEzbuZ1P"
      },
      "source": [
        "<h2 id=\"Question_1\">Question 1</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsPWG7hPuZ1Q"
      },
      "source": [
        "<b>Prepare a pre-trained resnet18 model :</b>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhU5EWFNuZ1Q"
      },
      "source": [
        "<b>Step 1</b>: Load the pre-trained model <code>resnet18</code> Set the parameter <code>pretrained</code> to true:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "sUpQgu64uZ1Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "d82d601bc374446f9c9a9a66dfdea79d",
            "3c4091fc73914846af66216aaea35b7a",
            "c0d058c2c0754332bb2879b741ce7996",
            "7062637f034447a182b8fd8a6430eba6",
            "1eb0a8653a804d35b9492d5acf793771",
            "e42fdbc835e542358be4991049330053",
            "f5db8e741ec742dc907c0c5f4a3eb7dd",
            "8d6c1bbf47974945885dc38c3bfb98d8",
            "836f6cf7875d436099d22057f383bc82",
            "21cdb0b303cb448e98accf50aea3860c",
            "98f54891c2604468ad7918e0bd8ecafe"
          ]
        },
        "outputId": "f28dc492-b7a2-4f28-e7ec-b09238cd6026"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d82d601bc374446f9c9a9a66dfdea79d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Step 1: Load the pre-trained model resnet18\n",
        "model = models.resnet18(pretrained=True)\n",
        "# Type your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nndJzSw4uZ1R"
      },
      "source": [
        "<b>Step 2</b>: Set the attribute <code>requires_grad</code> to <code>False</code>. As a result, the parameters will not be affected by training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "eWKpJZAKuZ1R"
      },
      "outputs": [],
      "source": [
        "# Step 2: Set the parameter cannot be trained for the pre-trained model\n",
        "for params in model.parameters():\n",
        "  params.requires_grad=False\n",
        "# Type your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDbWp6HMuZ1R"
      },
      "source": [
        "<code>resnet18</code> is used to classify 1000 different objects; as a result, the last layer has 1000 outputs.  The 512 inputs come from the fact that the previously hidden layer has 512 outputs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUlbwQbruZ1S"
      },
      "source": [
        "<b>Step 3</b>: Replace the output layer <code>model.fc</code> of the neural network with a <code>nn.Linear</code> object, to classify 2 different classes. For the parameters <code>in_features </code> remember the last hidden layer has 512 neurons.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Ik3Eugn1uZ1S"
      },
      "outputs": [],
      "source": [
        "model.fc = nn.Linear(512,2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uA3_3_1auZ1S"
      },
      "source": [
        "Print out the model in order to show whether you get the correct answer.<br> <b>(Your peer reviewer is going to mark based on what you print here.)</b>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "JszZNEhkuZ1S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6879799a-7d74-44e5-e267-ea4e988b1fdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FfXowAbuZ1T"
      },
      "source": [
        "<h2 id=\"Question_2\">Question 2: Train the Model</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVdL7qTGuZ1T"
      },
      "source": [
        "In this question you will train your, model:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RhIkcVLuZ1T"
      },
      "source": [
        "<b>Step 1</b>: Create a cross entropy criterion function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "xEdZAWViuZ1U"
      },
      "outputs": [],
      "source": [
        "# Step 1: Create the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Type your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHTdBQgNuZ1U"
      },
      "source": [
        "<b>Step 2</b>: Create a training loader and validation loader object, the batch size should have 100 samples each.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "racMmVbquZ1U"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(dataset= train_dataset, batch_size = 100)\n",
        "validation_loader = DataLoader(dataset= validation_dataset, batch_size = 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7JHSMsLuZ1V"
      },
      "source": [
        "<b>Step 3</b>: Use the following optimizer to minimize the loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "0uSZwDZEuZ1V"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam([parameters  for parameters in model.parameters() if parameters.requires_grad],lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pBt35MouZ1V"
      },
      "source": [
        "<!--Empty Space for separating topics-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbKoxEvbuZ1V"
      },
      "source": [
        "**Complete the following code to calculate  the accuracy on the validation data for one epoch; this should take about 45 minutes. Make sure you calculate the accuracy on the validation data.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "i5rH3d-QuZ1W"
      },
      "outputs": [],
      "source": [
        "n_epochs=1\n",
        "loss_list=[]\n",
        "accuracy_list=[]\n",
        "correct=0\n",
        "N_test=len(validation_dataset)\n",
        "N_train=len(train_dataset)\n",
        "start_time = time.time()\n",
        "#n_epochs\n",
        "\n",
        "Loss=0\n",
        "start_time = time.time()\n",
        "for epoch in range(n_epochs):\n",
        "    for x, y in train_loader:\n",
        "\n",
        "        model.train() \n",
        "        #clear gradient\n",
        "        optimizer.zero_grad() \n",
        "     \n",
        "        #make a prediction \n",
        "\n",
        "        z = model(x)\n",
        "   \n",
        "        # calculate loss \n",
        "        loss = criterion(z, y)\n",
        "        # calculate gradients of parameters \n",
        "        loss.backward()\n",
        "        # update parameters \n",
        "        optimizer.step()\n",
        "        loss_list.append(loss.data)\n",
        "    correct=0\n",
        "    for x_test, y_test in validation_loader:\n",
        "        # set model to eval \n",
        "        model.eval()\n",
        "        #make a prediction \n",
        "        z = model(x_test)\n",
        "        #find max \n",
        "        _, yhat = torch.max(z, 1)\n",
        "        model.train()\n",
        "       \n",
        "        #Calculate misclassified  samples in mini-batch \n",
        "        correct +=(yhat==y_test).sum().item()\n",
        "        \n",
        "   \n",
        "    accuracy=correct/N_test\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fanC_iuuZ1W"
      },
      "source": [
        "<b>Print out the Accuracy and plot the loss stored in the list <code>loss_list</code> for every iteration and take a screen shot.</b>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "JDJS4QDbuZ1X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30c7b815-162d-47f7-f67d-6ea57be104d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9954"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "XBgDGw3_uZ1X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "56888a15-b2c4-482d-96d6-25c191be3155"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(loss_list)\n",
        "plt.xlabel(\"iteration\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCTmnA2buZ1Y"
      },
      "source": [
        "<h2 id=\"Question_3\">Question 3:Find the misclassified samples</h2> \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0agZswrTuZ1Y"
      },
      "source": [
        "<b>Identify the first four misclassified samples using the validation data:</b>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "tapLhoIVuZ1Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84da8d96-9a19-4f3e-f9a7-f74105fe1b96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yhat : tensor([1]) x : tensor([[[[1.1358, 1.2899, 1.4098,  ..., 0.9988, 0.9988, 0.9988],\n",
            "          [1.0673, 1.2728, 1.4269,  ..., 0.9988, 1.0159, 1.0159],\n",
            "          [0.9646, 1.2043, 1.4098,  ..., 0.7933, 0.8276, 0.8618],\n",
            "          ...,\n",
            "          [1.2214, 1.1872, 1.1358,  ..., 0.9474, 0.9817, 1.0331],\n",
            "          [1.2557, 1.2385, 1.1872,  ..., 0.8961, 0.9303, 0.9817],\n",
            "          [1.3070, 1.2899, 1.2557,  ..., 0.8276, 0.8789, 0.9303]],\n",
            "\n",
            "         [[1.2381, 1.3957, 1.5182,  ..., 1.0805, 1.0805, 1.0805],\n",
            "          [1.1681, 1.3782, 1.5357,  ..., 1.0630, 1.0980, 1.0980],\n",
            "          [1.0630, 1.3081, 1.5182,  ..., 0.8529, 0.9055, 0.9405],\n",
            "          ...,\n",
            "          [1.3081, 1.2731, 1.2206,  ..., 1.0630, 1.0980, 1.1506],\n",
            "          [1.3431, 1.3256, 1.2731,  ..., 1.0105, 1.0455, 1.0980],\n",
            "          [1.3957, 1.3782, 1.3431,  ..., 0.9405, 0.9930, 1.0455]],\n",
            "\n",
            "         [[1.3328, 1.4897, 1.6117,  ..., 1.1062, 1.1062, 1.1062],\n",
            "          [1.2631, 1.4722, 1.6291,  ..., 1.1062, 1.1237, 1.1237],\n",
            "          [1.1585, 1.4025, 1.6117,  ..., 0.8971, 0.9319, 0.9668],\n",
            "          ...,\n",
            "          [1.3154, 1.2805, 1.2282,  ..., 1.0714, 1.1062, 1.1585],\n",
            "          [1.3502, 1.3328, 1.2805,  ..., 1.0191, 1.0539, 1.1062],\n",
            "          [1.4025, 1.3851, 1.3502,  ..., 0.9494, 1.0017, 1.0539]]]]) y :  tensor([0])\n",
            "yhat : tensor([1]) x : tensor([[[[1.2214, 1.1872, 1.1700,  ..., 0.9646, 0.9474, 0.9303],\n",
            "          [1.1872, 1.1700, 1.1529,  ..., 0.9988, 0.9817, 0.9646],\n",
            "          [1.1529, 1.1529, 1.1529,  ..., 1.0331, 1.0331, 1.0159],\n",
            "          ...,\n",
            "          [1.1358, 1.1187, 1.0844,  ..., 1.0331, 1.1015, 1.1700],\n",
            "          [1.1529, 1.1187, 1.0844,  ..., 1.0331, 1.1015, 1.1700],\n",
            "          [1.1529, 1.1187, 1.1015,  ..., 1.0331, 1.1015, 1.1700]],\n",
            "\n",
            "         [[1.1856, 1.1506, 1.1155,  ..., 0.9055, 0.8880, 0.8704],\n",
            "          [1.1506, 1.1331, 1.0980,  ..., 0.9405, 0.9230, 0.9055],\n",
            "          [1.1155, 1.1155, 1.0980,  ..., 0.9755, 0.9755, 0.9580],\n",
            "          ...,\n",
            "          [1.1506, 1.1331, 1.0980,  ..., 1.0105, 1.0805, 1.1506],\n",
            "          [1.1681, 1.1331, 1.0980,  ..., 1.0105, 1.0805, 1.1506],\n",
            "          [1.1681, 1.1331, 1.1155,  ..., 1.0105, 1.0805, 1.1506]],\n",
            "\n",
            "         [[1.0888, 1.0539, 1.0539,  ..., 0.9145, 0.8971, 0.8797],\n",
            "          [1.0539, 1.0365, 1.0365,  ..., 0.9494, 0.9319, 0.9145],\n",
            "          [1.0191, 1.0191, 1.0365,  ..., 0.9842, 0.9842, 0.9668],\n",
            "          ...,\n",
            "          [1.1411, 1.1237, 1.0888,  ..., 1.0191, 1.0888, 1.1585],\n",
            "          [1.1585, 1.1237, 1.0888,  ..., 1.0191, 1.0888, 1.1585],\n",
            "          [1.1585, 1.1237, 1.1062,  ..., 1.0191, 1.0888, 1.1585]]]]) y :  tensor([0])\n",
            "yhat : tensor([1]) x : tensor([[[[0.2111, 0.2111, 0.1939,  ..., 0.2282, 0.2282, 0.2111],\n",
            "          [0.0912, 0.1254, 0.1597,  ..., 0.2282, 0.2282, 0.2111],\n",
            "          [0.0227, 0.0912, 0.1597,  ..., 0.1768, 0.1768, 0.1768],\n",
            "          ...,\n",
            "          [0.1597, 0.1597, 0.1597,  ..., 0.1939, 0.1597, 0.1083],\n",
            "          [0.1254, 0.1254, 0.1254,  ..., 0.3309, 0.2796, 0.2282],\n",
            "          [0.0912, 0.0741, 0.0741,  ..., 0.3309, 0.2796, 0.2282]],\n",
            "\n",
            "         [[0.3803, 0.3803, 0.3627,  ..., 0.3627, 0.3627, 0.3452],\n",
            "          [0.2577, 0.2927, 0.3277,  ..., 0.3627, 0.3627, 0.3452],\n",
            "          [0.1877, 0.2577, 0.3277,  ..., 0.3102, 0.3102, 0.3102],\n",
            "          ...,\n",
            "          [0.3277, 0.3277, 0.3277,  ..., 0.3627, 0.3277, 0.2752],\n",
            "          [0.2927, 0.2927, 0.2927,  ..., 0.5028, 0.4503, 0.3978],\n",
            "          [0.2577, 0.2402, 0.2402,  ..., 0.5028, 0.4503, 0.3978]],\n",
            "\n",
            "         [[0.5834, 0.5834, 0.5659,  ..., 0.5485, 0.5485, 0.5311],\n",
            "          [0.4614, 0.4962, 0.5311,  ..., 0.5485, 0.5485, 0.5311],\n",
            "          [0.3916, 0.4614, 0.5311,  ..., 0.4962, 0.4962, 0.4962],\n",
            "          ...,\n",
            "          [0.5311, 0.5311, 0.5311,  ..., 0.5659, 0.5311, 0.4788],\n",
            "          [0.4962, 0.4962, 0.4962,  ..., 0.7054, 0.6531, 0.6008],\n",
            "          [0.4614, 0.4439, 0.4439,  ..., 0.7054, 0.6531, 0.6008]]]]) y :  tensor([0])\n",
            "yhat : tensor([1]) x : tensor([[[[1.2728, 1.2728, 1.2728,  ..., 1.1872, 1.1872, 1.1872],\n",
            "          [1.2557, 1.2557, 1.2557,  ..., 1.1700, 1.1700, 1.1700],\n",
            "          [1.2214, 1.2385, 1.2385,  ..., 1.1529, 1.1529, 1.1529],\n",
            "          ...,\n",
            "          [0.9474, 0.9474, 0.9646,  ..., 1.2043, 1.2043, 1.2043],\n",
            "          [0.9132, 0.9132, 0.9303,  ..., 1.2043, 1.2043, 1.2043],\n",
            "          [0.8618, 0.8618, 0.8789,  ..., 1.2043, 1.2043, 1.2043]],\n",
            "\n",
            "         [[1.3431, 1.3431, 1.3431,  ..., 1.1856, 1.1856, 1.1856],\n",
            "          [1.3256, 1.3256, 1.3256,  ..., 1.1681, 1.1681, 1.1681],\n",
            "          [1.2906, 1.3081, 1.3081,  ..., 1.1506, 1.1506, 1.1506],\n",
            "          ...,\n",
            "          [1.0455, 1.0455, 1.0630,  ..., 1.2031, 1.2031, 1.2031],\n",
            "          [1.0105, 1.0105, 1.0280,  ..., 1.2031, 1.2031, 1.2031],\n",
            "          [0.9580, 0.9580, 0.9755,  ..., 1.2031, 1.2031, 1.2031]],\n",
            "\n",
            "         [[1.4548, 1.4548, 1.4548,  ..., 1.3154, 1.3154, 1.3154],\n",
            "          [1.4374, 1.4374, 1.4374,  ..., 1.2980, 1.2980, 1.2980],\n",
            "          [1.4025, 1.4200, 1.4200,  ..., 1.2805, 1.2805, 1.2805],\n",
            "          ...,\n",
            "          [1.1759, 1.1759, 1.1934,  ..., 1.3328, 1.3328, 1.3328],\n",
            "          [1.1411, 1.1411, 1.1585,  ..., 1.3328, 1.3328, 1.3328],\n",
            "          [1.0888, 1.0888, 1.1062,  ..., 1.3328, 1.3328, 1.3328]]]]) y :  tensor([0])\n"
          ]
        }
      ],
      "source": [
        "count = 0\n",
        "for x, y in DataLoader(dataset = validation_dataset, batch_size=1):\n",
        "  z = model(x)\n",
        "  _, yhat = torch.max(z, 1)\n",
        "  if yhat != y:\n",
        "    print(\"yhat :\",yhat, \"x :\", x, \"y : \", y)\n",
        "    count += 1\n",
        "  if count == 4:\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AO2YXGaeuZ1Z"
      },
      "source": [
        "<a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/share-notebooks.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork20647850-2021-01-01\"> CLICK HERE </a> Click here to see how to share your notebook.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-L9eIbEuZ1Z"
      },
      "source": [
        "<h2>About the Authors:</h2> \n",
        "\n",
        "<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork20647850-2021-01-01\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6Md0UkNuZ1Z"
      },
      "source": [
        "## Change Log\n",
        "\n",
        "| Date (YYYY-MM-DD) | Version | Changed By | Change Description                                          |\n",
        "| ----------------- | ------- | ---------- | ----------------------------------------------------------- |\n",
        "| 2020-09-21        | 2.0     | Shubham    | Migrated Lab to Markdown and added to course repo in GitLab |\n",
        "\n",
        "<hr>\n",
        "\n",
        "## <h3 align=\"center\"> © IBM Corporation 2020. All rights reserved. <h3/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGZy5mcLuZ1a"
      },
      "source": [
        "Copyright © 2018 <a href=\"https://cognitiveclass.ai/?utm_medium=dswb&utm_source=bducopyrightlink&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork20647850-2021-01-01&utm_campaign=bdu\">cognitiveclass.ai</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork20647850-2021-01-01\">MIT License</a>.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "ai FINAL PROJ.ipynb",
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d82d601bc374446f9c9a9a66dfdea79d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3c4091fc73914846af66216aaea35b7a",
              "IPY_MODEL_c0d058c2c0754332bb2879b741ce7996",
              "IPY_MODEL_7062637f034447a182b8fd8a6430eba6"
            ],
            "layout": "IPY_MODEL_1eb0a8653a804d35b9492d5acf793771"
          }
        },
        "3c4091fc73914846af66216aaea35b7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e42fdbc835e542358be4991049330053",
            "placeholder": "​",
            "style": "IPY_MODEL_f5db8e741ec742dc907c0c5f4a3eb7dd",
            "value": "100%"
          }
        },
        "c0d058c2c0754332bb2879b741ce7996": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d6c1bbf47974945885dc38c3bfb98d8",
            "max": 46830571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_836f6cf7875d436099d22057f383bc82",
            "value": 46830571
          }
        },
        "7062637f034447a182b8fd8a6430eba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21cdb0b303cb448e98accf50aea3860c",
            "placeholder": "​",
            "style": "IPY_MODEL_98f54891c2604468ad7918e0bd8ecafe",
            "value": " 44.7M/44.7M [00:01&lt;00:00, 64.8MB/s]"
          }
        },
        "1eb0a8653a804d35b9492d5acf793771": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e42fdbc835e542358be4991049330053": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5db8e741ec742dc907c0c5f4a3eb7dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d6c1bbf47974945885dc38c3bfb98d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "836f6cf7875d436099d22057f383bc82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "21cdb0b303cb448e98accf50aea3860c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98f54891c2604468ad7918e0bd8ecafe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}